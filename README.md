🌿 Ecology-RAG: 生态学文献智能知识库助手
这是一个基于 Ollama 与 LangChain 构建的本地检索增强生成（RAG）系统。本项目专门为生态学研究者设计，旨在通过 AI 助力长篇学术文献的深度阅读与知识检索。

✨ 核心特性
专业学术语气：系统内置“资深生态学教授”角色，回答风格严谨、逻辑清晰，支持中英文双语对话。

长文本支持：针对生态学长论文优化，配置了 32k (32768) 上下文窗口，确保模型能够完整“读懂”多篇参考文献。

流式交互体验：支持类似 ChatGPT 的流式文本输出，回答过程实时可见。

灵活编辑功能：支持对已发送的提问进行二次编辑，保存后系统会自动删除旧回答并重新检索生成。

本地隐私保护：所有计算均通过 Ollama 在本地完成，无需上传数据至云端，确保科研数据的私密性。

实时统计：侧边栏实时显示知识库中的文件总数及向量片段（Chunks）数量。

🛠️ 技术栈
模型层：Qwen 2.5 (32B Instruct)

嵌入层：Nomic-Embed-Text

后端框架：FastAPI

RAG 框架：LangChain 0.3+ (Core, Ollama, Chroma, Text-Splitters)

向量数据库：ChromaDB

前端：原生 HTML5 / CSS3 / JavaScript (Vanilla JS)
